{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pde-solver GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6EL64U9d/k6rhc2s1fbPS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulvoliva/Public-PDE-Solvers/blob/main/pde_solver_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "AknCux-lYNSn",
        "outputId": "f17134f0-09e0-4c80-bc86-b447f298e5c5"
      },
      "source": [
        "!pip install numpy==1.19.4"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.19.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/86/753182c9085ba4936c0076269a571613387cdb77ae2bf537448bfd63472c/numpy-1.19.4-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5MB 309kB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "Successfully installed numpy-1.19.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtnaD6t_Tn7b",
        "outputId": "a2914c5c-a366-4e47-a938-887211de5c0d"
      },
      "source": [
        "pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.6.0+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.6.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (708.0MB)\n",
            "\u001b[K     |████████████████████████████████| 708.0MB 27kB/s \n",
            "\u001b[?25hCollecting torchvision==0.7.0+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.7.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 25.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed torch-1.6.0+cu101 torchvision-0.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrQt5so-R8tf",
        "outputId": "b62db291-282b-4891-b163-3dadf2a28f7d"
      },
      "source": [
        "!pip install ray==1.0.1.post1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ray==1.0.1.post1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/87/44476ad712acc1f7957cbf88d307d4a0283a740487cf85d710d0211d0135/ray-1.0.1.post1-cp36-cp36m-manylinux1_x86_64.whl (23.1MB)\n",
            "\u001b[K     |████████████████████████████████| 23.1MB 140kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from ray==1.0.1.post1) (2.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray==1.0.1.post1) (1.0.2)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from ray==1.0.1.post1) (0.9.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from ray==1.0.1.post1) (2.6.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from ray==1.0.1.post1) (3.12.4)\n",
            "Collecting py-spy>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/b7/2056a6f06adb93f679f2a1e415dd33219b7c66ba69b8fd2ff1668b8064ed/py_spy-0.3.4-py2.py3-none-manylinux1_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 42.6MB/s \n",
            "\u001b[?25hCollecting aioredis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/64/1b1612d0a104f21f80eb4c6e1b6075f2e6aba8e228f46f229cfd3fdac859/aioredis-1.3.1-py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from ray==1.0.1.post1) (3.0.12)\n",
            "Collecting aiohttp-cors\n",
            "  Downloading https://files.pythonhosted.org/packages/13/e7/e436a0c0eb5127d8b491a9b83ecd2391c6ff7dcd5548dfaec2080a2340fd/aiohttp_cors-0.7.0-py3-none-any.whl\n",
            "Requirement already satisfied: google in /usr/local/lib/python3.6/dist-packages (from ray==1.0.1.post1) (2.0.3)\n",
            "Collecting gpustat\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/69/d8c849715171aeabd61af7da080fdc60948b5a396d2422f1f4672e43d008/gpustat-0.6.0.tar.gz (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray==1.0.1.post1) (3.13)\n",
            "Collecting colorful\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/8e/e386e248266952d24d73ed734c2f5513f34d9557032618c8910e605dfaf6/colorful-0.5.4-py2.py3-none-any.whl (201kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 41.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.6/dist-packages (from ray==1.0.1.post1) (1.32.0)\n",
            "Collecting redis<3.5.0,>=3.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/05/1fc7feedc19c123e7a95cfc9e7892eb6cdd2e5df4e9e8af6384349c1cc3d/redis-3.4.1-py2.py3-none-any.whl (71kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.2MB/s \n",
            "\u001b[?25hCollecting opencensus\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/d6/b952f11b29c3a0cbec5620de3c4260cecd8c4329d83e91587edb48691e15/opencensus-0.7.12-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 45.8MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/e6/d4b6235d776c9b33f853e603efede5aac5a34f71ca9d3877adb30492eb4e/aiohttp-3.7.3-cp36-cp36m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 28.9MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from ray==1.0.1.post1) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from ray==1.0.1.post1) (1.19.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->ray==1.0.1.post1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ray==1.0.1.post1) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ray==1.0.1.post1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ray==1.0.1.post1) (1.24.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->ray==1.0.1.post1) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->ray==1.0.1.post1) (51.3.3)\n",
            "Collecting async-timeout\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting hiredis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/7d/6acf1c8d4f2fb327ff6feec000b4c56a20628fbe966a4c7cd16c0b80343c/hiredis-1.1.0-cp36-cp36m-manylinux2010_x86_64.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from google->ray==1.0.1.post1) (4.6.3)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from gpustat->ray==1.0.1.post1) (7.352.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from gpustat->ray==1.0.1.post1) (5.4.8)\n",
            "Collecting blessings>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/03/74/489f85a78247609c6b4f13733cbf3ba0d864b11aa565617b645d6fdf2a4a/blessings-1.7-py3-none-any.whl\n",
            "Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from opencensus->ray==1.0.1.post1) (1.16.0)\n",
            "Collecting opencensus-context==0.1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/f1/33/990f1bd9e7ee770fc8d3c154fc24743a96f16a0e49e14e1b7540cc2fdd93/opencensus_context-0.1.2-py2.py3-none-any.whl\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/35/b22524d6b9cacfb4c5eff413a069bbc17c6ea628e54da5c6c989998ced5f/multidict-5.1.0-cp36-cp36m-manylinux2014_x86_64.whl (141kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 40.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray==1.0.1.post1) (20.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray==1.0.1.post1) (3.7.4.3)\n",
            "Collecting idna-ssl>=1.0; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/46/03/07c4894aae38b0de52b52586b24bf189bb83e4ddabfe2e2c8f2419eec6f4/idna-ssl-1.1.0.tar.gz\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/08/52b26b44bce7b818b410aee37c5e424c9ea420c557bca97dc2adac29b151/yarl-1.6.3-cp36-cp36m-manylinux2014_x86_64.whl (293kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 30.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==1.0.1.post1) (1.52.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==1.0.1.post1) (1.17.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray==1.0.1.post1) (2018.9)\n",
            "Collecting contextvars; python_version >= \"3.6\" and python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray==1.0.1.post1) (4.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray==1.0.1.post1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray==1.0.1.post1) (4.6)\n",
            "Collecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray==1.0.1.post1) (0.4.8)\n",
            "Building wheels for collected packages: gpustat, idna-ssl, contextvars\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-0.6.0-cp36-none-any.whl size=12622 sha256=f09b3fb4f56dbc6253f1d40fa1aecd721798358d1494e14b99839451723b83ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/b4/d5/fb5b7f1d040f2ff20687e3bad6867d63155dbde5a7c10f4293\n",
            "  Building wheel for idna-ssl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-cp36-none-any.whl size=3163 sha256=51f28ad53b31a25d3bc9da642dbf25ce0b503e962cf88577803abf07de1b082a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/00/b3/32d613e19e08a739751dd6bf998cfed277728f8b2127ad4eb7\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7667 sha256=94afa9504142dfeef50acd9b045bc4ecf0f33575cf5342d8086be9cf9fd83565\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "Successfully built gpustat idna-ssl contextvars\n",
            "Installing collected packages: py-spy, async-timeout, hiredis, aioredis, multidict, idna-ssl, yarl, aiohttp, aiohttp-cors, blessings, gpustat, colorful, redis, immutables, contextvars, opencensus-context, opencensus, colorama, ray\n",
            "Successfully installed aiohttp-3.7.3 aiohttp-cors-0.7.0 aioredis-1.3.1 async-timeout-3.0.1 blessings-1.7 colorama-0.4.4 colorful-0.5.4 contextvars-2.4 gpustat-0.6.0 hiredis-1.1.0 idna-ssl-1.1.0 immutables-0.14 multidict-5.1.0 opencensus-0.7.12 opencensus-context-0.1.2 py-spy-0.3.4 ray-1.0.1.post1 redis-3.4.1 yarl-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5ZzJnIqRqbf",
        "outputId": "deea1006-ee7e-4271-ae53-f9f1291aec68"
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\r\u001b[K     |█                               | 10kB 18.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 18.0MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 9.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 235kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 256kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 276kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 296kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 307kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (51.3.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fziFKbTMggxs",
        "outputId": "96298b46-9f5b-4339-e5ca-78a6f40aac35"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jan 21 10:34:01 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDz1ebMVRHks",
        "outputId": "45818c85-e28f-4637-c035-3c6fb3de504d"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"PDE Solver.ipynb\n",
        "Here we will take the time components in the third axis\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import os\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from torch.autograd import grad\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\"\"\"# Exact solution u(x) for the example PDE\n",
        "we conduct a experiment on solving a IBVP with nonlinear diffusion-reaction equation and boundary condition involving time:\n",
        "\\begin{equation}\n",
        "\\left\\{\\begin{array}{ll}\n",
        "u_{t}-\\Delta u-u^{2}=f(x, y, t), & \\text { in } \\Omega \\times[0, T] \\\\\n",
        "u(x, y, t)=g(x, y, t), & \\text { on } \\partial \\Omega \\times[0, T] \\\\\n",
        "u(x, y, 0)=h(x, y), & \\text { in } \\Omega\n",
        "\\end{array}\\right.\n",
        "\\end{equation}\n",
        "where $\\Omega=(-1,1)^{2} \\subset \\mathbb{R}^{2}$. In this test, we give the definition of $f(x,y,t)=\\left(\\pi^{2}-2\\right) \\sin \\left(\\frac{\\pi}{2} x\\right) \\cos \\left(\\frac{\\pi}{2} y\\right) e^{-t} - 4 \\sin ^{2}\\left(\\frac{\\pi}{2} x\\right) \\cos \\left(\\frac{\\pi}{2} y\\right) e^{-2 t}$ in $\\Omega \\times[0, T]$, $g(x,y,t)=2 \\sin \\left(\\frac{\\pi}{2} x\\right) \\cos \\left(\\frac{\\pi}{2} y\\right) e^{-t}$ on $\\partial \\Omega \\times[0, T]$ and $h(x,y)=2 \\sin \\left(\\frac{\\pi}{2} x\\right) \\cos \\left(\\frac{\\pi}{2} y\\right)$ in $\\Omega$. And the true solution is $u(x,y,t)=2 \\sin \\left(\\frac{\\pi}{2} x\\right) \\cos \\left(\\frac{\\pi}{2} y\\right) e^{-t}$.\n",
        "\n",
        "# PDE Setup\n",
        "\"\"\"\n",
        "\n",
        "'''\n",
        "# I use this to get the shape of the tensor when I debug\n",
        "old_repr = torch.Tensor.__repr__\n",
        "def tensor_info(tensor):\n",
        "    return repr(tensor.shape)[6:] + ' ' + repr(tensor.dtype)[6:] + '@' + str(tensor.device) + '\\n' + old_repr(tensor)\n",
        "torch.Tensor.__repr__ = tensor_info\n",
        "#'''\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(device)\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "# TODO: implement cuda\n",
        "\n",
        "def func_u_sol(xt):\n",
        "    l = xt.shape[0]\n",
        "    u = 2 * torch.sin(math.pi / 2 * xt[:, 0, :]) * torch.cos(math.pi / 2 * xt[:, 1, :]) * torch.exp(xt[:, 2, :])\n",
        "    return(u)\n",
        "\n",
        "\n",
        "# We denote spatial coordinates with time as 'xt' and 'x' without\n",
        "\n",
        "def func_f(xt):\n",
        "    l = xt.shape[0]\n",
        "    f = (math.pi ** 2 - 2) * torch.sin(math.pi / 2 * xt[:, 0, :]) * torch.cos(math.pi / 2 * xt[:, 1, :]) * torch.exp(\n",
        "        -xt[:, 2, :]) - 4 * torch.sin(math.pi / 2 * xt[:, 0, :]) ** 2 * torch.cos(math.pi / 2 * xt[:, 1, :]) * torch.exp(-xt[:, 2, :])\n",
        "    return(f)\n",
        "\n",
        "\n",
        "def func_g(boundary_xt):\n",
        "    return func_u_sol(boundary_xt)\n",
        "\n",
        "\n",
        "def func_h(x):\n",
        "    h = 2 * torch.sin(math.pi / 2 * x[:, 0]) * torch.cos(math.pi / 2 * x[:, 1])\n",
        "    return h\n",
        "\n",
        "\n",
        "def func_w(x):  # returns 1 for positions in the domain and 0 otherwise\n",
        "    lens = x.shape[0]\n",
        "    w_bool = torch.gt(1 - torch.abs(x[:, 0]), torch.zeros(lens).to(device)) & torch.gt(torch.abs(x[:, 0]), torch.zeros(lens).to(device))\n",
        "    w_val = torch.where(w_bool, 1 - torch.abs(x[:, 0]) + torch.abs(x[:, 0]), torch.zeros(lens).to(device))\n",
        "    return (w_val.view(-1, 1))\n",
        "\n",
        "\n",
        "\"\"\"# Domain\"\"\"\n",
        "\n",
        "T0 = 0  # if this is ignored it is always set as T0=0\n",
        "T = 1\n",
        "\n",
        "# Set up for a square\n",
        "up = 1.0\n",
        "down = -1.0\n",
        "dim = 2\n",
        "domain_sample_size = 8000  # 25000\n",
        "t_mesh_size = 11\n",
        "boundary_sample_size = 40  # 250\n",
        "\n",
        "# defining the training domain\n",
        "x0_domain = torch.Tensor(domain_sample_size, dim).uniform_(down, up)\n",
        "x0_domain.requires_grad_()\n",
        "\n",
        "x_domain_train = x0_domain.unsqueeze(2).repeat(1, 1, t_mesh_size)\n",
        "\n",
        "t = torch.linspace(T0, T, t_mesh_size).unsqueeze(1).unsqueeze(2).view(1, 1, t_mesh_size).repeat(domain_sample_size, 1, 1)\n",
        "xt_domain_train = torch.cat((x_domain_train, t), dim=1)\n",
        "\n",
        "xt_domain_train = xt_domain_train.to(device)\n",
        "\n",
        "# defining the training boundary\n",
        "x0_boundary_side = torch.Tensor(boundary_sample_size, dim - 1).uniform_(down, up)\n",
        "x0_boundary_side.requires_grad_()\n",
        "\n",
        "x0_boundary_left = torch.cat((torch.ones(x0_boundary_side.size()) * down, x0_boundary_side), 1)\n",
        "x0_boundary_right = torch.cat((torch.ones(x0_boundary_side.size()) * up, x0_boundary_side), 1)\n",
        "x0_boundary_down = torch.cat((x0_boundary_side, torch.ones(x0_boundary_side.size()) * down), 1)\n",
        "x0_boundary_up = torch.cat((x0_boundary_side, torch.ones(x0_boundary_side.size()) * up), 1)\n",
        "\n",
        "x0_boundary = torch.cat((x0_boundary_left, x0_boundary_right, x0_boundary_down, x0_boundary_up), 0)\n",
        "\n",
        "x_boundary_train = x0_boundary.unsqueeze(2).repeat(1, 1, t_mesh_size)\n",
        "xt_boundary_train = torch.cat((x_boundary_train, t[:4*boundary_sample_size, :, :]), dim=1)\n",
        "xt_boundary_train = xt_boundary_train.to(device)\n",
        "\n",
        "\n",
        "# Validation data Sets\n",
        "val_domain_size = int(domain_sample_size * 0.3)\n",
        "val_boundary_size = int(boundary_sample_size * 0.3)\n",
        "\n",
        "x0_domain_val = torch.Tensor(val_domain_size, dim).uniform_(down, up)\n",
        "x0_domain_val.requires_grad_()\n",
        "\n",
        "x_domain_val = x0_domain_val.unsqueeze(2).repeat(1, 1, t_mesh_size)\n",
        "xt_domain_val = torch.cat((x_domain_val, t[:val_domain_size, :, :]), dim=1).to(device)\n",
        "\n",
        "# defining the validation boundary\n",
        "x0_boundary_side = torch.Tensor(val_boundary_size, dim - 1).uniform_(down, up)\n",
        "x0_boundary_side.requires_grad_()\n",
        "\n",
        "x0_boundary_left = torch.cat((torch.ones(x0_boundary_side.size()) * down, x0_boundary_side), 1)\n",
        "x0_boundary_right = torch.cat((torch.ones(x0_boundary_side.size()) * up, x0_boundary_side), 1)\n",
        "x0_boundary_down = torch.cat((x0_boundary_side, torch.ones(x0_boundary_side.size()) * down), 1)\n",
        "x0_boundary_up = torch.cat((x0_boundary_side, torch.ones(x0_boundary_side.size()) * up), 1)\n",
        "\n",
        "x0_boundary = torch.cat((x0_boundary_left, x0_boundary_right, x0_boundary_down, x0_boundary_up), 0)\n",
        "\n",
        "x_boundary_val = x0_boundary.unsqueeze(2).repeat(1, 1, t_mesh_size)\n",
        "xt_boundary_val = torch.cat((x_boundary_val, t[:4*val_boundary_size, :, :]), dim=1).to(device)\n",
        "\n",
        "xv = xt_domain_train[:, 0, :].clone().detach()\n",
        "yv = xt_domain_train[:, 1, :].clone().detach()\n",
        "tv = xt_domain_train[:, 2, :].clone().detach()\n",
        "xv = xv.requires_grad_(True).to(device)\n",
        "yv = yv.requires_grad_(True).to(device)\n",
        "tv = tv.requires_grad_(True).to(device)\n",
        "\n",
        "\n",
        "xu = xv.clone().detach()\n",
        "yu = yv.clone().detach()\n",
        "tu = tv.clone().detach()\n",
        "xu.requires_grad_(True).to(device)\n",
        "yu.requires_grad_(True).to(device)\n",
        "tu.requires_grad_(True).to(device)\n",
        "\n",
        "x_val = xt_domain_val[:, 0, :].clone().detach().requires_grad_(True).to(device)\n",
        "y_val = xt_domain_val[:, 1, :].clone().detach().requires_grad_(True).to(device)\n",
        "t_val = xt_domain_val[:, 2, :].clone().detach().requires_grad_(True).to(device)\n",
        "\n",
        "\"\"\"# Defining the Model\"\"\"\n",
        "\n",
        "\n",
        "class generator(torch.nn.Module):  # this makes the u function\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.num_layers = config['u_layers']\n",
        "        self.hidden_dim = config['u_hidden_dim']\n",
        "        self.input = torch.nn.Linear(dim+1, self.hidden_dim)\n",
        "        self.hidden = torch.nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "        self.output = torch.nn.Linear(self.hidden_dim, 1)\n",
        "        self.net = torch.nn.Sequential(*[\n",
        "            self.input,\n",
        "            *[torch.nn.ReLU(), self.hidden] * self.num_layers,\n",
        "            torch.nn.Tanh(),\n",
        "            self.output\n",
        "\n",
        "        ])\n",
        "\n",
        "    def forward(self, x0, y0, t):\n",
        "        #t = t.unsqueeze(1).unsqueeze(2).view(1, 1, t_mesh_size).repeat(1, 2, 1)\n",
        "        #x_ = torch.cat((x0.unsqueeze(2).view(-1, 1, t_mesh_size), y0.unsqueeze(2).view(-1, 1, t_mesh_size)), dim=1)\n",
        "        inp = torch.cat((x0.unsqueeze(2), y0.unsqueeze(2), t.unsqueeze(2)), dim=2)\n",
        "        x = self.net(inp)\n",
        "        return x\n",
        "\n",
        "    def backward(self, retain_graph=True):\n",
        "        self.loss.backward(retain_graph=retain_graph)\n",
        "        return (self.loss)\n",
        "\n",
        "\n",
        "class discriminator(torch.nn.Module):  # this makes the v function\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.num_layers = config['v_layers']\n",
        "        self.hidden_dim = config['v_hidden_dim']\n",
        "        self.input = torch.nn.Linear(dim+1, self.hidden_dim)\n",
        "        self.hidden = torch.nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "        self.output = torch.nn.Linear(self.hidden_dim, 1)\n",
        "        self.net = torch.nn.Sequential(*[\n",
        "            self.input,\n",
        "            *[torch.nn.ReLU(), self.hidden] * self.num_layers,\n",
        "            torch.nn.Tanh(),\n",
        "            self.output\n",
        "\n",
        "        ])\n",
        "\n",
        "    def forward(self, x0, y0, t):\n",
        "        # t = t.unsqueeze(1).unsqueeze(2).view(1, 1, t_mesh_size).repeat(1, 2, 1)\n",
        "        # x_ = torch.cat((x0.unsqueeze(2).view(-1, 1, t_mesh_size), y0.unsqueeze(2).view(-1, 1, t_mesh_size)), dim=1)\n",
        "        inp = torch.cat((x0.unsqueeze(2), y0.unsqueeze(2), t.unsqueeze(2)), dim=2)\n",
        "        x = self.net(inp)\n",
        "        return x\n",
        "\n",
        "    def backward(self, retain_graph=True):\n",
        "        self.loss.backward(retain_graph=retain_graph)\n",
        "        return (self.loss)\n",
        "'''\n",
        "#Search space based on the WAN Paper\n",
        "config = {\n",
        "    'alpha': tune.loguniform(1e3, 1e7),\n",
        "    'u_layers': 7,\n",
        "    'u_hidden_dim': 20,\n",
        "    'v_layers': 7,\n",
        "    'v_hidden_dim': 50,\n",
        "    'n1': 2,  # tune.choice([2, 4, 6, 8, 10, 14, 20]),\n",
        "    'n2': 1,  # tune.sample_from(lambda spec: int(spec.config.n1/2)),\n",
        "    'u_rate': tune.loguniform(0.0001, 0.1),\n",
        "    'v_rate': tune.loguniform(0.0001, 0.1),\n",
        "    'num_workers': 2,\n",
        "    'num_cpu_per_worker': 1\n",
        "}\n",
        "'''\n",
        "\n",
        "#Result of Hyperparameter search\n",
        "config = {\n",
        "    'u_layers': 7,\n",
        "    'u_hidden_dim': 20,\n",
        "    'v_layers': 7,\n",
        "    'v_hidden_dim': 50,\n",
        "    'n1': 10,\n",
        "    'n2': 5,\n",
        "    'alpha': 30.296,\n",
        "    'u_rate': 0.0032223,  # 0.00015\n",
        "    'v_rate': 0.0064395  # 0.00015\n",
        "}\n",
        "\n",
        "'''\n",
        "#Original WAN paper\n",
        "config = {\n",
        "    'u_layers': 7,\n",
        "    'u_hidden_dim': 20,\n",
        "    'v_layers': 7,\n",
        "    'v_hidden_dim': 50,\n",
        "    'n1': 10,  # 2,\n",
        "    'n2': 5,  # 6, 1\n",
        "    'alpha': 1e5,\n",
        "    'u_rate': 0.015,  # 0.00015\n",
        "    'v_rate': 0.04   # 0.00015\n",
        "}\n",
        "\n",
        "#One hyperparameter result\n",
        "config = {\n",
        "    'u_layers': 5,\n",
        "    'u_hidden_dim': 20,\n",
        "    'v_layers': 6,\n",
        "    'v_hidden_dim': 16,\n",
        "    'n1': 10,\n",
        "    'n2': 6,\n",
        "    'u_rate': 0.0025703,\n",
        "    'v_rate': 0.00593051}\n",
        "\n",
        "#Search Space for the above\n",
        "config = {\n",
        "    'u_layers': tune.choice([4, 5, 6, 7, 8]),\n",
        "    'u_hidden_dim': tune.choice([20, 21, 23]),\n",
        "    'v_layers': tune.choice([5, 6, 7, 8]),\n",
        "    'v_hidden_dim': tune.choice([13, 15, 16]),\n",
        "    'n1': 10,\n",
        "    'n2': 5,\n",
        "    'u_rate': tune.loguniform(1e-3, 1e-2),\n",
        "    'v_rate': tune.loguniform(1e-3, 1e-2)\n",
        "}\n",
        "'''\n",
        "\n",
        "\"\"\"# Loss Function\"\"\"\n",
        "\n",
        "# TODO: ensure loss is normalised\n",
        "def I(y_output_u, y_output_v, xt, xv, yv, tv, xu, yu, tu):\n",
        "    shape = [y_output_u.shape[0], t_mesh_size, dim]\n",
        "    shape[-1] = shape[-1] - 1\n",
        "    y_output_u.retain_grad()\n",
        "    y_output_v.retain_grad()\n",
        "    phi = y_output_v * func_w(xt[:, :, 0]).unsqueeze(2).repeat(1, t_mesh_size, 1)\n",
        "    y_output_u.backward(torch.ones(shape).to(device), retain_graph=True)\n",
        "    du_x = xu.grad\n",
        "    du_y = yu.grad\n",
        "    phi.backward(torch.ones(shape).to(device), retain_graph=True)\n",
        "    dphi_x = xv.grad\n",
        "    dphi_y = yv.grad\n",
        "    dphi_t = tv.grad.unsqueeze(2)\n",
        "    s1 = y_output_u[:, -1, :] * phi[:, -1, :] - func_h(xt[:, 0, :]).unsqueeze(1) * phi[:, 0, :]\n",
        "    s2 = (y_output_u * dphi_t)/t_mesh_size  # for t does this make sense?\n",
        "    Lap = du_x * dphi_x + du_y * dphi_y\n",
        "    s3 = (T-T0)*(Lap.unsqueeze(2) + y_output_u * y_output_u * phi - func_f(xt).unsqueeze(2) * phi)/t_mesh_size\n",
        "    I = torch.sum(s1 - torch.sum(s2 - s3, 1), 0)\n",
        "    xu.grad.data.zero_()\n",
        "    yu.grad.data.zero_()\n",
        "    xv.grad.data.zero_()\n",
        "    yv.grad.data.zero_()\n",
        "    tv.grad.data.zero_()\n",
        "    return I\n",
        "\n",
        "def L_init(y_output_u, config):\n",
        "    #u_net = generator(config)\n",
        "    return torch.mean((y_output_u[:, 0, 0] - func_h(xt_domain_train[:, :2, 0])) ** 2)\n",
        "\n",
        "\n",
        "def L_bdry(u_net):\n",
        "    return torch.mean((u_net(xt_boundary_train[:, 0, :], xt_boundary_train[:, 1, :], xt_boundary_train[:, 2, :]) -\n",
        "                       func_g(xt_boundary_train).unsqueeze(2)) ** 2)\n",
        "\n",
        "\n",
        "def L_int(y_output_u, y_output_v, xt=xt_domain_train, xv=xv, yv=yv, tv=tv, xu=xu, yu=yu, tu=tu):\n",
        "    # x needs to be the set of points set plugged into net_u and net_v\n",
        "    return torch.log((I(y_output_u, y_output_v, xt, xv, yv, tv, xu, yu, tu)) ** 2) - torch.log(torch.sum(y_output_v ** 2))\n",
        "\n",
        "\n",
        "#gamma = 25    # 1e5*boundary_sample_size*4  # 25\n",
        "#alpha = gamma\n",
        "\n",
        "\n",
        "def L(y_output_u, y_output_v, u_net, alpha, gamma):\n",
        "    return L_int(y_output_u, y_output_v) + gamma * L_init(y_output_u, config) + alpha * L_bdry(\n",
        "        u_net)\n",
        "\n",
        "\n",
        "def Loss_u(y_output_u, y_output_v, u_net, alpha, gamma):\n",
        "    return L(y_output_u, y_output_v, u_net, alpha, gamma)\n",
        "\n",
        "\n",
        "def Loss_v(y_output_u, y_output_v):\n",
        "    return -L_int(y_output_u, y_output_v)\n",
        "\n",
        "# TODO: identify the best n1, n2 (n2=n1/2) and best alpha and gamma\n",
        "\n",
        "\"\"\"# Training\"\"\"\n",
        "\n",
        "iteration = 2000\n",
        "\n",
        "x_mesh = torch.linspace(0, 1, 50, requires_grad=True)\n",
        "mesh1, mesh2 = torch.meshgrid(x_mesh, x_mesh)\n",
        "mesh_1= torch.reshape(mesh1, [-1,1])\n",
        "mesh_2= torch.reshape(mesh2, [-1,1])\n",
        "t = torch.ones(2500, 1)\n",
        "xt_test = torch.cat((mesh_1, mesh_2, t), dim = 1).unsqueeze(2)\n",
        "\n",
        "def train(config, checkpoint_dir=None):\n",
        "    n1 = config['n1']\n",
        "    n2 = config['n2']\n",
        "\n",
        "    # neural network models\n",
        "    u_net = generator(config).to(device)\n",
        "    v_net = discriminator(config).to(device)\n",
        "\n",
        "    # optimizers for WAN\n",
        "    optimizer_u = torch.optim.Adam(u_net.parameters(), lr=config['u_rate'])\n",
        "    optimizer_v = torch.optim.Adam(v_net.parameters(), lr=config['v_rate'])\n",
        "\n",
        "    #scheduler_u = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_u, factor=0.5, patience=30)\n",
        "    #scheduler_v = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_v, factor=0.5, patience=30)\n",
        "\n",
        "    prediction_u = u_net(xu, yu, tu)\n",
        "    prediction_v = v_net(xv, yv, tv)\n",
        "\n",
        "    Loss = 0\n",
        "\n",
        "    for k in range(iteration):\n",
        "\n",
        "        for i in range(n1):\n",
        "            loss_u = Loss_u(prediction_u, prediction_v, u_net, config['alpha'], config['alpha'])\n",
        "            optimizer_u.zero_grad()\n",
        "            loss_u.backward(retain_graph=True)\n",
        "            optimizer_u.step()\n",
        "            #scheduler_u.step(loss_u)\n",
        "            prediction_u = u_net(xu, yu, tu)\n",
        "\n",
        "        for j in range(n2):\n",
        "            loss_v = Loss_v(prediction_u, prediction_v)\n",
        "            optimizer_v.zero_grad()\n",
        "            loss_v.backward(retain_graph=True)\n",
        "            optimizer_v.step()\n",
        "            #scheduler_v.step(loss_v)\n",
        "            prediction_v = v_net(xv, yv, tv)\n",
        "\n",
        "        Loss += 0.1*loss_u\n",
        "\n",
        "        if k % 10 == 0:\n",
        "            #torch.save(u_net.state_dict(), \"./net_u.pth\")\n",
        "            #torch.save(v_net.state_dict(), \"./net_v.pth\")\n",
        "            print(k, loss_u.data, loss_v.data)\n",
        "            # print('learning rate at %d epoch：%f' % (k, optimizer_u.param_groups[0]['lr']))\n",
        "            # print('learning rate at %d epoch：%f' % (k, optimizer_v.param_groups[0]['lr']))\n",
        "            #tune.report(Loss=Loss.item())\n",
        "            Loss = 0\n",
        "            error_test = torch.mean(\n",
        "                torch.sqrt(torch.square((func_u_sol(xt_domain_train) - prediction_u.data.squeeze(2))))).data\n",
        "            print(\"error test \" + str(error_test))\n",
        "            '''\n",
        "            print(device)\n",
        "            with tune.checkpoint_dir(k) as checkpoint_dir:\n",
        "                path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
        "                torch.save((u_net.state_dict(), v_net.state_dict()), path)\n",
        "            \n",
        "            #PATHg = os.path.join('/Users/paulvalsecchi/Desktop/Project/Models alpha=25', 'generator_{}.pth'.format(k))\n",
        "            #PATHd = os.path.join('/Users/paulvalsecchi/Desktop/Project/Models alpha=25', 'discriminator_{}.pth'.format(k))\n",
        "\n",
        "            #torch.save(u_net.state_dict(), PATHg)\n",
        "            #torch.save(v_net.state_dict(), PATHd)\n",
        "\n",
        "\n",
        "        #error_test = torch.mean(torch.sqrt(torch.square((func_u_sol(xt_domain_train) - prediction_u.data.squeeze(2))))).data\n",
        "        error_test = torch.mean(torch.sqrt(torch.square(func_u_sol(xt_domain_val)-u_net(x_val, y_val, t_val).data.squeeze(2))))\n",
        "        #print(error_test)\n",
        "        #tune.report(Loss=float(loss_u.detach().numpy()))\n",
        "\n",
        "\n",
        "        #EarlyStopping(loss_u, u_net)\n",
        "        '''\n",
        "\n",
        "train(config)\n",
        "\n",
        "\n",
        "'''\n",
        "u_net = generator(config)\n",
        "PATHg = os.path.join('/Users/paulvalsecchi/Desktop/Project/Models', 'generator_1000.pth')\n",
        "u_net.load_state_dict(torch.load(PATHg))\n",
        "u_net.eval()\n",
        "\n",
        "'''\n",
        "plt.plot(func_u_sol(xt_test).data.numpy())\n",
        "plt.plot(u_net(xt_test[:, 0, 0].unsqueeze(1), xt_test[:, 1, 0].unsqueeze(1), xt_test[:, 2, 0].unsqueeze(1)).squeeze(2).data.numpy())\n",
        "plt.show()\n",
        "\n",
        "'''\n",
        "# Hyperparameter Optimization\n",
        "\n",
        "# Best trial config: {'u_layers': 5, 'u_hidden_dim': 20, 'v_layers': 5, 'v_hidden_dim': 5, 'n1': 10, 'n2': 5, 'u_rate': 0.0002133670132946601, 'v_rate': 0.0006349874886164373}\n",
        "# Best trial config: {'u_layers': 2, 'u_hidden_dim': 20, 'v_layers': 4, 'v_hidden_dim': 20, 'n1': 10, 'n2': 7, 'u_rate': 0.0006756995220370141, 'v_rate': 0.0002804879090959305}\n",
        "# Best trial config: {'u_layers': 4, 'u_hidden_dim': 23, 'v_layers': 4, 'v_hidden_dim': 15, 'n1': 10, 'n2': 6, 'u_rate': 0.003370553415547106, 'v_rate': 0.009087847200586583}\n",
        "# Best trial config: {'u_layers': 7, 'u_hidden_dim': 30, 'v_layers': 7, 'v_hidden_dim': 50, 'n1': 10, 'n2': 6, 'u_rate': 0.07933644599535282, 'v_rate': 0.03159263256623099}\n",
        "\n",
        "\n",
        "analysis = tune.run(\n",
        "    train,\n",
        "    num_samples=200,\n",
        "    scheduler=ASHAScheduler(metric=\"Loss\", mode=\"min\", grace_period=10, max_t=200),\n",
        "    config=config,\n",
        "    verbose=2,\n",
        "    resources_per_trial = {\"cpu\":2} #,\"gpu\":1}\n",
        ")\n",
        "\n",
        "best_trial = analysis.get_best_trial(metric=\"Loss\", mode=\"min\")\n",
        "print(\"Best trial config: {}\".format(best_trial.config))\n",
        "\n",
        "best_trained_generator = generator(best_trial.config)\n",
        "best_trained_discriminator = discriminator(best_trial.config)\n",
        "\n",
        "best_checkpoint_dir = best_trial.checkpoint.value\n",
        "generator_state, discriminator_state = torch.load(os.path.join(\n",
        "    best_checkpoint_dir, \"checkpoint\"))\n",
        "\n",
        "\n",
        "\n",
        "# Obtain a trial dataframe from all run trials of this `tune.run` call.\n",
        "dfs = analysis.trial_dataframes\n",
        "\n",
        "\n",
        "ax = None  # This plots everything on the same plot\n",
        "for d in dfs.values():\n",
        "    ax = d.mean_error.plot(ax=ax, legend=False)\n",
        "ax.set_xlabel(\"Epochs\")\n",
        "ax.set_ylabel(\"Mean Error\")\n",
        "\n",
        "\n",
        "x_mesh = torch.linspace(down, up, 500, requires_grad=True)\n",
        "mesh1, mesh2 = torch.meshgrid(x_mesh, x_mesh)\n",
        "mesh_1 = torch.reshape(mesh1, [-1, 1]).repeat(1, 11).unsqueeze(2).view(-1, 1, 11)\n",
        "mesh_2 = torch.reshape(mesh2, [-1, 1]).repeat(1, 11).unsqueeze(2).view(-1, 1, 11)\n",
        "t = torch.linspace(0, 1, 11).unsqueeze(1).view(1, -1).repeat(250000, 1).unsqueeze(2).view(-1, 1, 11)\n",
        "xt_comparison = torch.cat((mesh_1, mesh_2, t), dim=1)\n",
        "\n",
        "u_net = generator(config)\n",
        "'''\n",
        "\n",
        "error = torch.sqrt(torch.square(func_u_sol(xt_comparison)-u_net(xt_comparison[:, 0, :], xt_comparison[:, 1, :], xt_comparison[:, 2, :]).squeeze(2)))\n",
        "# mean_error = torch.mean(error, dim=1)\n",
        "# mean_error = mean_error.view(500, 500)\n",
        "l_error = error[:, -1].view(500,500)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "cset=plt.contourf(mesh1.data.numpy(),mesh2.data.numpy(), l_error.data.numpy(), 500, cmap='winter')\n",
        "\n",
        "plt.colorbar(cset)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "True\n",
            "0 tensor([133.1307], device='cuda:0') tensor([-7.0305], device='cuda:0')\n",
            "error test tensor(1.3880, device='cuda:0')\n",
            "10 tensor([16.1506], device='cuda:0') tensor([-7.8067], device='cuda:0')\n",
            "error test tensor(0.6644, device='cuda:0')\n",
            "20 tensor([10.1781], device='cuda:0') tensor([-8.7759], device='cuda:0')\n",
            "error test tensor(0.5381, device='cuda:0')\n",
            "30 tensor([9.5432], device='cuda:0') tensor([-8.1748], device='cuda:0')\n",
            "error test tensor(0.5721, device='cuda:0')\n",
            "40 tensor([9.6108], device='cuda:0') tensor([-8.7363], device='cuda:0')\n",
            "error test tensor(0.5929, device='cuda:0')\n",
            "50 tensor([9.5738], device='cuda:0') tensor([-7.8691], device='cuda:0')\n",
            "error test tensor(0.6181, device='cuda:0')\n",
            "60 tensor([9.3341], device='cuda:0') tensor([-8.9492], device='cuda:0')\n",
            "error test tensor(0.6366, device='cuda:0')\n",
            "70 tensor([9.3182], device='cuda:0') tensor([-8.8181], device='cuda:0')\n",
            "error test tensor(0.6603, device='cuda:0')\n",
            "80 tensor([9.4617], device='cuda:0') tensor([-8.8898], device='cuda:0')\n",
            "error test tensor(0.6774, device='cuda:0')\n",
            "90 tensor([9.3698], device='cuda:0') tensor([-8.8845], device='cuda:0')\n",
            "error test tensor(0.6840, device='cuda:0')\n",
            "100 tensor([9.8339], device='cuda:0') tensor([-9.6504], device='cuda:0')\n",
            "error test tensor(0.7058, device='cuda:0')\n",
            "110 tensor([10.0708], device='cuda:0') tensor([-9.8063], device='cuda:0')\n",
            "error test tensor(0.7274, device='cuda:0')\n",
            "120 tensor([9.9351], device='cuda:0') tensor([-9.2741], device='cuda:0')\n",
            "error test tensor(0.7222, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}