{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pde-solver GAN 2.1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOne0cPhtVuRVxQvEamCmX8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulvoliva/Public-PDE-Solvers/blob/main/pde_solver_GAN_2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07ZEXKuHJgMP"
      },
      "source": [
        "!pip install numpy==1.19.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKIPhDDdJqa_"
      },
      "source": [
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdpDjS9qJsSh"
      },
      "source": [
        "!pip install ray==1.0.1.post1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-2DQY2WJtAW"
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPddfEjXJu3v"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCKODDN_J0Z7"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import os\n",
        "from ray import tune\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from torch.autograd import grad\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from Earlystop import EarlyStopping\n",
        "from itertools import product\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgeRD8TvKQC9"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(device)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox5fJQvDKFOZ"
      },
      "source": [
        "# Exact solution u(x) for the example PDE\n",
        "we conduct a experiment on solving a IBVP with nonlinear diffusion-reaction equation and boundary condition involving time:\n",
        "\\begin{equation}\n",
        "\\left\\{\\begin{array}{ll}\n",
        "u_{t}-\\Delta u-u^{2}=f(x, y, t), & \\text { in } \\Omega \\times[0, T] \\\\\n",
        "u(x, y, t)=g(x, y, t), & \\text { on } \\partial \\Omega \\times[0, T] \\\\\n",
        "u(x, y, 0)=h(x, y), & \\text { in } \\Omega\n",
        "\\end{array}\\right.\n",
        "\\end{equation}\n",
        "where $\\Omega=(-1,1)^{2} \\subset \\mathbb{R}^{2}$. In this test, we give the definition of $f(x,y,t)=\\left(\\pi^{2}-2\\right) \\sin \\left(\\frac{\\pi}{2} x\\right) \\cos \\left(\\frac{\\pi}{2} y\\right) e^{-t} - 4 \\sin ^{2}\\left(\\frac{\\pi}{2} x\\right) \\cos \\left(\\frac{\\pi}{2} y\\right) e^{-2 t}$ in $\\Omega \\times[0, T]$, $g(x,y,t)=2 \\sin \\left(\\frac{\\pi}{2} x\\right) \\cos \\left(\\frac{\\pi}{2} y\\right) e^{-t}$ on $\\partial \\Omega \\times[0, T]$ and $h(x,y)=2 \\sin \\left(\\frac{\\pi}{2} x\\right) \\cos \\left(\\frac{\\pi}{2} y\\right)$ in $\\Omega$. And the true solution is $u(x,y,t)=2 \\sin \\left(\\frac{\\pi}{2} x\\right) \\cos \\left(\\frac{\\pi}{2} y\\right) e^{-t}$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA7FRrKtKKxD"
      },
      "source": [
        "# PDE Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95H8umFIKRF9"
      },
      "source": [
        "def func_u_sol(xt):\n",
        "    l = xt.shape[0]\n",
        "    u = 2 * torch.sin(math.pi / 2 * xt[:, 0, :]) * torch.cos(math.pi / 2 * xt[:, 1, :]) * torch.exp(xt[:, 2, :])\n",
        "    return(u)\n",
        "\n",
        "# We denote spatial coordinates with time as 'xt' and 'x' without\n",
        "\n",
        "def func_f(xt):\n",
        "    l = xt.shape[0]\n",
        "    f = (math.pi ** 2 - 2) * torch.sin(math.pi / 2 * xt[:, 0, :]) * torch.cos(math.pi / 2 * xt[:, 1, :]) * torch.exp(\n",
        "        -xt[:, 2, :]) - 4 * torch.sin(math.pi / 2 * xt[:, 0, :]) ** 2 * torch.cos(math.pi / 2 * xt[:, 1, :]) ** 2 * torch.exp(-xt[:, 2, :])\n",
        "    return(f)\n",
        "\n",
        "\n",
        "def func_g(boundary_xt):\n",
        "    return func_u_sol(boundary_xt)\n",
        "\n",
        "\n",
        "def func_h(x):\n",
        "    h = 2 * torch.sin(math.pi / 2 * x[:, 0]) * torch.cos(math.pi / 2 * x[:, 1])\n",
        "    return h\n",
        "\n",
        "def func_c(y_output_u):\n",
        "    return -y_output_u\n",
        "\n",
        "def func_w(x):  # returns 1 for positions in the domain and 0 otherwise\n",
        "    lens = x.shape[0]\n",
        "    w_bool = torch.gt(1 - torch.abs(x[:, 0]), torch.zeros(lens).to(device)) & torch.gt(torch.abs(x[:, 0]), torch.zeros(lens).to(device))\n",
        "    w_val = torch.where(w_bool, 1 - torch.abs(x[:, 0]) + torch.abs(x[:, 0]), torch.zeros(lens).to(device))\n",
        "    return (w_val.view(-1, 1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJksdDK-KVdb"
      },
      "source": [
        "# Domain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfilU2OtKVNU"
      },
      "source": [
        "T0 = 0  # if this is ignored it is always set as T0=0\n",
        "T = 1\n",
        "\n",
        "# Set up for a square\n",
        "up = 1.0\n",
        "down = -1.0\n",
        "dim = 2\n",
        "domain_sample_size = 1000  # 25000\n",
        "t_mesh_size = 11\n",
        "boundary_sample_size = 40  # 250\n",
        "num_workers = 4\n",
        "\n",
        "assert domain_sample_size%num_workers==0 & 4*boundary_sample_size%num_workers==0, \"To make the dataloader work num_workers needs to divide the size of the domain and boundary samples\"\n",
        "\n",
        "# defining the training domain\n",
        "x0_domain = torch.Tensor(domain_sample_size, dim).uniform_(down, up)\n",
        "x0_domain.requires_grad_()\n",
        "\n",
        "x_domain_train = x0_domain.unsqueeze(2).repeat(1, 1, t_mesh_size)\n",
        "\n",
        "t = torch.linspace(T0, T, t_mesh_size).unsqueeze(1).unsqueeze(2).view(1, 1, t_mesh_size).repeat(domain_sample_size, 1, 1)\n",
        "xt_domain_train = torch.cat((x_domain_train, t), dim=1)\n",
        "\n",
        "xt_domain_train = xt_domain_train.to(device)\n",
        "\n",
        "# defining the training boundary\n",
        "x0_boundary_side = torch.Tensor(boundary_sample_size, dim - 1).uniform_(down, up)\n",
        "x0_boundary_side.requires_grad_()\n",
        "\n",
        "x0_boundary_left = torch.cat((torch.ones(x0_boundary_side.size()) * down, x0_boundary_side), 1)\n",
        "x0_boundary_right = torch.cat((torch.ones(x0_boundary_side.size()) * up, x0_boundary_side), 1)\n",
        "x0_boundary_down = torch.cat((x0_boundary_side, torch.ones(x0_boundary_side.size()) * down), 1)\n",
        "x0_boundary_up = torch.cat((x0_boundary_side, torch.ones(x0_boundary_side.size()) * up), 1)\n",
        "\n",
        "x0_boundary = torch.cat((x0_boundary_left, x0_boundary_right, x0_boundary_down, x0_boundary_up), 0)\n",
        "\n",
        "x_boundary_train = x0_boundary.unsqueeze(2).repeat(1, 1, t_mesh_size)\n",
        "xt_boundary_train = torch.cat((x_boundary_train, t[:4*boundary_sample_size, :, :]), dim=1)\n",
        "xt_boundary_train = xt_boundary_train.detach().to(device)\n",
        "\n",
        "\n",
        "# Validation data Sets\n",
        "val_domain_size = int(domain_sample_size * 0.3)\n",
        "val_boundary_size = int(boundary_sample_size * 0.3)\n",
        "\n",
        "x0_domain_val = torch.Tensor(val_domain_size, dim).uniform_(down, up)\n",
        "x0_domain_val.requires_grad_()\n",
        "\n",
        "x_domain_val = x0_domain_val.unsqueeze(2).repeat(1, 1, t_mesh_size)\n",
        "xt_domain_val = torch.cat((x_domain_val, t[:val_domain_size, :, :]), dim=1).to(device)\n",
        "\n",
        "# defining the validation boundary\n",
        "x0_boundary_side = torch.Tensor(val_boundary_size, dim - 1).uniform_(down, up)\n",
        "x0_boundary_side.requires_grad_()\n",
        "\n",
        "x0_boundary_left = torch.cat((torch.ones(x0_boundary_side.size()) * down, x0_boundary_side), 1)\n",
        "x0_boundary_right = torch.cat((torch.ones(x0_boundary_side.size()) * up, x0_boundary_side), 1)\n",
        "x0_boundary_down = torch.cat((x0_boundary_side, torch.ones(x0_boundary_side.size()) * down), 1)\n",
        "x0_boundary_up = torch.cat((x0_boundary_side, torch.ones(x0_boundary_side.size()) * up), 1)\n",
        "\n",
        "x0_boundary = torch.cat((x0_boundary_left, x0_boundary_right, x0_boundary_down, x0_boundary_up), 0)\n",
        "\n",
        "x_boundary_val = x0_boundary.unsqueeze(2).repeat(1, 1, t_mesh_size)\n",
        "xt_boundary_val = torch.cat((x_boundary_val, t[:4*val_boundary_size, :, :]), dim=1).to(device)\n",
        "\n",
        "xv = xt_domain_train[:, 0, :].clone().detach()\n",
        "yv = xt_domain_train[:, 1, :].clone().detach()\n",
        "tv = xt_domain_train[:, 2, :].clone().detach()\n",
        "\n",
        "xu = xv.clone().detach()\n",
        "yu = yv.clone().detach()\n",
        "tu = tv.clone().detach()\n",
        "\n",
        "x_error = xv.clone().detach()\n",
        "y_error = yv.clone().detach()\n",
        "t_error = tv.clone().detach()\n",
        "\n",
        "X = [xu, yu, tu]\n",
        "XV = [xv, yv, tv]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtXQM4Z2LCRM"
      },
      "source": [
        "class Comb_loader(Dataset):\n",
        "    def __init__(self, X, XV, border):\n",
        "        super(Comb_loader).__init__()\n",
        "        self.interior = X\n",
        "        self.interior2 = XV\n",
        "        self.border = border\n",
        "        self.end_int = X[0].shape[0]\n",
        "        self.end_bor = border.shape[0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return num_workers\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        worker_info = torch.utils.data.get_worker_info()\n",
        "        if worker_info is None:\n",
        "            start_int = 0\n",
        "            start_bor = 0\n",
        "            end_int = self.end_int\n",
        "            end_bor = self.end_bor\n",
        "        else:\n",
        "            int_size, bor_size = int(math.ceil((self.end_int) / float(worker_info.num_workers))), int(math.ceil((self.end_bor) / float(worker_info.num_workers)))\n",
        "            worker_id = worker_info.id\n",
        "            start_int, start_bor = worker_id*int_size, worker_id*bor_size\n",
        "            end_int, end_bor = min(start_int+int_size, self.end_int), min(start_bor+bor_size, self.end_bor)\n",
        "        return self.interior[0][start_int:end_int, :], self.interior[1][start_int:end_int, :], \\\n",
        "               self.interior[0][start_int:end_int, :], self.interior2[0][start_int:end_int, :], \\\n",
        "               self.interior2[1][start_int:end_int, :], self.interior2[0][start_int:end_int, :], \\\n",
        "               self.border[start_bor:end_bor, :, :]\n",
        "\n",
        "data = Comb_loader(X, XV, xt_boundary_train)\n",
        "ds = DataLoader(data, num_workers=num_workers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CErOuwhBLGnR"
      },
      "source": [
        "x_val = xt_domain_val[:, 0, :].clone().detach().requires_grad_(True).to(device)\n",
        "y_val = xt_domain_val[:, 1, :].clone().detach().requires_grad_(True).to(device)\n",
        "t_val = xt_domain_val[:, 2, :].clone().detach().requires_grad_(True).to(device)\n",
        "\n",
        "# this is meant to be a d by d-dimensional array containing domain_sample_size by t_mesh_size by 1 tensors\n",
        "a1, a2 = torch.cat((torch.ones(1, 1, domain_sample_size, t_mesh_size, 1), torch.zeros(1, 1, domain_sample_size, t_mesh_size, 1)), dim=1), torch.cat((torch.zeros(1, 1, domain_sample_size, t_mesh_size, 1), torch.ones(1, 1, domain_sample_size, t_mesh_size, 1)), dim=1)\n",
        "a = torch.cat((a1, a2), dim=0).to(device)\n",
        "\n",
        "# this is meant to be a d-dimensional containing domain_sample_size by t_mesh_size by 1 tensors\n",
        "b = torch.cat((torch.zeros(1, domain_sample_size, t_mesh_size, 1), torch.zeros(1, domain_sample_size, t_mesh_size, 1)), dim=0).to(device)\n",
        "\n",
        "x_setup = xv.clone().detach().to(device)\n",
        "y_setup = yv.clone().detach().to(device)\n",
        "t_setup = tv.clone().detach().to(device)\n",
        "\n",
        "xyt_setup = torch.cat((x_setup.unsqueeze(2).view(-1, 1, t_mesh_size), y_setup.unsqueeze(2).view(-1, 1, t_mesh_size), t_setup.unsqueeze(2).view(-1, 1, t_mesh_size)), dim=1)\n",
        "\n",
        "h = func_h(xyt_setup[:, :, 0]).to(device)\n",
        "f = func_f(xyt_setup).to(device)\n",
        "g = func_g(xt_boundary_train.clone().detach().to(device)).unsqueeze(2).to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwMujnDFLHhL"
      },
      "source": [
        "# Defining the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7BlXU2JLLhS"
      },
      "source": [
        "def init_weights(layer):\n",
        "    if type(layer) == torch.nn.Linear:\n",
        "        torch.nn.init.xavier_uniform_(layer.weight)\n",
        "        layer.bias.data.fill_(0)\n",
        "\n",
        "class generator(torch.nn.Module):\n",
        "    '''\n",
        "    This function is the generator and will be the function that will give us the weak solution. It will be referred to\n",
        "    as the u function further on. The function takes in x,y,t points and returns what we estimate to be the value of the\n",
        "    solution at that point. This model can intake an arbitrarily long list of these inputs but all the lists need to be\n",
        "    equally long. The input shape is [N, 1].\n",
        "    '''\n",
        "    def __init__(self, config):\n",
        "        '''\n",
        "        Args in config:\n",
        "            'u_layers' (int): this is the number of identical layers self.hidden with ReLU activation\n",
        "            'u_hidden_dim' (int): this is the dimensionality of the self.hidden linear layer.\n",
        "        '''\n",
        "        super().__init__()\n",
        "        self.num_layers = config['u_layers']\n",
        "        self.hidden_dim = config['u_hidden_dim']\n",
        "        self.input = torch.nn.Linear(dim+1, self.hidden_dim)\n",
        "        self.hidden = torch.nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "        self.output = torch.nn.Linear(self.hidden_dim, 1)\n",
        "        self.net = torch.nn.Sequential(*[\n",
        "            self.input,\n",
        "            *[torch.nn.ReLU(), self.hidden] * self.num_layers,\n",
        "            torch.nn.Tanh(),\n",
        "            self.output\n",
        "\n",
        "        ])\n",
        "\n",
        "    def forward(self, x0, y0, t):\n",
        "        inp = torch.cat((x0.unsqueeze(2), y0.unsqueeze(2), t.unsqueeze(2)), dim=2)\n",
        "        x = self.net(inp)\n",
        "        return x\n",
        "\n",
        "    def backward(self, retain_graph=True):\n",
        "        self.loss.backward(retain_graph=retain_graph)\n",
        "        return (self.loss)\n",
        "\n",
        "\n",
        "class discriminator(torch.nn.Module):  # this makes the v function\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.num_layers = config['v_layers']\n",
        "        self.hidden_dim = config['v_hidden_dim']\n",
        "        self.input = torch.nn.Linear(dim+1, self.hidden_dim)\n",
        "        self.hidden = torch.nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "        self.output = torch.nn.Linear(self.hidden_dim, 1)\n",
        "        self.net = torch.nn.Sequential(*[\n",
        "            self.input,\n",
        "            *[torch.nn.ReLU(), self.hidden] * self.num_layers,\n",
        "            torch.nn.Tanh(),\n",
        "            self.output\n",
        "\n",
        "        ])\n",
        "\n",
        "    def forward(self, x0, y0, t):\n",
        "        inp = torch.cat((x0.unsqueeze(2), y0.unsqueeze(2), t.unsqueeze(2)), dim=2)\n",
        "        x = self.net(inp)\n",
        "        return x\n",
        "\n",
        "    def backward(self, retain_graph=True):\n",
        "        self.loss.backward(retain_graph=retain_graph)\n",
        "        return (self.loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHVKTfgoLQ1j"
      },
      "source": [
        "config = {\n",
        "    \"alpha\": 1e5, \n",
        "    \"u_layers\": 7, \n",
        "    \"u_hidden_dim\": 20, \n",
        "    \"v_layers\": 7, \n",
        "    \"v_hidden_dim\": 50, \n",
        "    \"n1\": 10, \n",
        "    \"n2\": 5, \n",
        "    \"u_rate\": 0.02, \n",
        "    \"v_rate\": 0.0015, \n",
        "    \"u_factor\": 0.9, \n",
        "    \"v_factor\": 0.95\n",
        "} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2pvyq9hL5OL"
      },
      "source": [
        "# Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llLb0pDLL4-G"
      },
      "source": [
        "def I(y_output_u, y_output_v, XV, X, ind, a=a, b=b,h=h, f=f, c=func_c):\n",
        "    y_output_u.retain_grad()\n",
        "    y_output_v.retain_grad()\n",
        "    N = y_output_u.shape[0]\n",
        "    phi = y_output_v * func_w(XV[0]).unsqueeze(2).repeat(1, t_mesh_size, 1)\n",
        "    y_output_u.backward(torch.ones_like(y_output_u).to(device), retain_graph=True)\n",
        "    du = {}\n",
        "    for i in range(dim):\n",
        "        du['du_'+str(i)] = X[i].grad\n",
        "    phi.backward(torch.ones_like(phi).to(device), retain_graph=True)\n",
        "    dphi = {}\n",
        "    for i in range(dim+1):\n",
        "        dphi['dphi_'+str(i)] = XV[i].grad\n",
        "    s1 = y_output_u[:, -1, :].squeeze(1) * phi[:, -1, :].squeeze(1) - h[ind*N:(ind+1)*N]\n",
        "    s2 = (y_output_u * dphi['dphi_2'].unsqueeze(2))/t_mesh_size  # for t does this make sense?\n",
        "    s31 = 0\n",
        "    for i,j in product(range(dim), repeat=2):\n",
        "        s31 += a[i, j, ind*N:(ind+1)*N, :, :] * dphi['dphi_'+str(i)].unsqueeze(2) * du['du_'+str(j)].unsqueeze(2)\n",
        "    s32 = 0\n",
        "    for i in range(dim):\n",
        "        s32 += b[i, ind*N:(ind+1)*N, :, :] * phi * du['du_'+str(i)].unsqueeze(2)\n",
        "    s3 = (T-T0)*(s31 + s32 + func_c(y_output_u) * y_output_u * phi - f[ind*N:(ind+1)*N, :].unsqueeze(2) * phi)/t_mesh_size\n",
        "    I = torch.sum(s1 - torch.sum(s2 - s3, 1).squeeze(1), 0)\n",
        "    for i in X:\n",
        "        i.grad.data.zero_()\n",
        "    for i in XV:\n",
        "        i.grad.data.zero_()\n",
        "    return I\n",
        "\n",
        "\n",
        "def L_init(y_output_u, ind, h=h):\n",
        "    N = y_output_u.shape[0]\n",
        "    return torch.mean((y_output_u[:, 0, :].squeeze(1) - h[ind*N:(ind+1)*N]) ** 2)\n",
        "\n",
        "\n",
        "def L_bdry(u_net, xt_boundary_train, ind, g=g):\n",
        "    return torch.mean((u_net(xt_boundary_train[:, 0, :], xt_boundary_train[:, 1, :], xt_boundary_train[:, 2, :]) - g) ** 2)\n",
        "\n",
        "\n",
        "def L_int(y_output_u, y_output_v, XV, X, ind):\n",
        "    # x needs to be the set of points set plugged into net_u and net_v\n",
        "    return torch.log((I(y_output_u, y_output_v, XV, X, ind)) ** 2) - torch.log(torch.sum(y_output_v ** 2))\n",
        "\n",
        "\n",
        "def Loss_u(y_output_u, y_output_v, u_net, alpha, gamma, xt_boundary_train, XV, X, ind):\n",
        "    return L_int(y_output_u, y_output_v, XV, X, ind) + gamma * L_init(y_output_u, ind) + alpha * L_bdry(u_net, xt_boundary_train, ind)\n",
        "\n",
        "def Loss_v(y_output_u, y_output_v, XV, X, ind):\n",
        "    return -L_int(y_output_u, y_output_v, XV, X, ind)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZDKmzkKL_7C"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFO9QbhJMCIJ"
      },
      "source": [
        "iteration = 4000\n",
        "\n",
        "x_mesh = torch.linspace(0, 1, 50, requires_grad=True)\n",
        "mesh1, mesh2 = torch.meshgrid(x_mesh, x_mesh)\n",
        "mesh_1= torch.reshape(mesh1, [-1,1])\n",
        "mesh_2= torch.reshape(mesh2, [-1,1])\n",
        "t = torch.ones(2500, 1)\n",
        "xt_test = torch.cat((mesh_1, mesh_2, t), dim = 1).unsqueeze(2).to(device)\n",
        "\n",
        "EarlyStop = EarlyStopping(patience=1, delta=10) #the delta is the maximum divergence that we will allow from our best average solution\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBYnZdVQMF08"
      },
      "source": [
        "def train(config, checkpoint_dir=None):\n",
        "    n1 = config['n1']\n",
        "    n2 = config['n2']\n",
        "\n",
        "    # neural network models\n",
        "    u_net = torch.nn.DataParallel(generator(config)).to(device)\n",
        "    v_net = torch.nn.DataParallel(discriminator(config)).to(device)\n",
        "\n",
        "    u_net.apply(init_weights)\n",
        "    v_net.apply(init_weights)\n",
        "\n",
        "    Loss = 0\n",
        "\n",
        "    for k in range(iteration):\n",
        "\n",
        "        # optimizers for WAN\n",
        "        optimizer_u = torch.optim.Adam(u_net.parameters(), lr=config['u_rate'])\n",
        "        optimizer_v = torch.optim.Adam(v_net.parameters(), lr=config['v_rate'])\n",
        "\n",
        "        scheduler_u = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_u, factor=config['u_factor'], patience=100)\n",
        "        scheduler_v = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_v, factor=config['v_factor'], patience=100)\n",
        "\n",
        "        for i in range(n1):\n",
        "            for ind, (xu, yu, tu, xv, yv, tv, btxy) in enumerate(ds):\n",
        "                xu, yu, tu, xv, yv, tv, btxy = xu.squeeze(0).requires_grad_(True).to(device), yu.squeeze(0).requires_grad_(True).to(device),\\\n",
        "                                               tu.squeeze(0).requires_grad_(True).to(device), xv.squeeze(0).requires_grad_(True).to(device),\\\n",
        "                                               yv.squeeze(0).requires_grad_(True).to(device), tv.squeeze(0).requires_grad_(True).to(device),\\\n",
        "                                               btxy.squeeze(0).requires_grad_(True).to(device)\n",
        "                X = [xu, yu, tu]\n",
        "                XV = [xv, yv, tv]\n",
        "                prediction_v = v_net(xv, yv, tv)\n",
        "                prediction_u = u_net(xu, yu, tu)\n",
        "                loss_u = Loss_u(prediction_u, prediction_v, u_net, config['alpha'], config['alpha'], xt_boundary_train, XV, X, ind)\n",
        "                optimizer_u.zero_grad()\n",
        "                loss_u.backward(retain_graph=True)\n",
        "                optimizer_u.step()\n",
        "                #print('learning rate: ', optimizer_u.param_groups[0]['lr'])\n",
        "                scheduler_u.step(loss_u)\n",
        "\n",
        "        for j in range(n2):\n",
        "            for ind, (xu, yu, tu, xv, yv, tv, btxy) in enumerate(ds):\n",
        "                xu, yu, tu, xv, yv, tv, btxy = xu.squeeze(0).requires_grad_(True).to(device), yu.squeeze(0).requires_grad_(True).to(device),\\\n",
        "                                               tu.squeeze(0).requires_grad_(True).to(device), xv.squeeze(0).requires_grad_(True).to(device),\\\n",
        "                                               yv.squeeze(0).requires_grad_(True).to(device), tv.squeeze(0).requires_grad_(True).to(device),\\\n",
        "                                               btxy.squeeze(0).requires_grad_(True).to(device)\n",
        "                X = [xu, yu, tu]\n",
        "                XV = [xv, yv, tv]\n",
        "                prediction_v = v_net(xv, yv, tv)\n",
        "                prediction_u = u_net(xu, yu, tu)\n",
        "                loss_v = Loss_v(prediction_u, prediction_v, XV, X, ind)\n",
        "                optimizer_v.zero_grad()\n",
        "                loss_v.backward(retain_graph=True)\n",
        "                optimizer_v.step()\n",
        "                scheduler_v.step(loss_v)\n",
        "\n",
        "        prediction_v = v_net(x_val, y_val, t_val)\n",
        "        prediction_u = u_net(x_val, y_val, t_val)\n",
        "        loss_u = Loss_u(prediction_u, prediction_v, u_net, 1, 1, xt_boundary_train, [x_val, y_val, t_val], [x_val, y_val, t_val], 0)\n",
        "        Loss += 0.1*loss_u.data\n",
        "\n",
        "        if k % 10 == 0:\n",
        "          print(k, loss_u.data, loss_v.data)\n",
        "          print(Loss)\n",
        "          prediction_u = u_net(x_error, y_error, t_error)\n",
        "          error_test = torch.mean(\n",
        "                torch.sqrt(torch.square((func_u_sol(xt_domain_train) - prediction_u.data.squeeze(2))))).data\n",
        "          print(\"error test \" + str(error_test))\n",
        "          if k != 0:\n",
        "              EarlyStop(Loss, u_net)\n",
        "          if EarlyStop.early_stop == True:\n",
        "              break\n",
        "          Loss = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBHwhbJYMW8c"
      },
      "source": [
        "train(config)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}